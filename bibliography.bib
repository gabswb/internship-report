@ARTICLE{ieee-754,
  author={},
  journal={IEEE Std 754-2019 (Revision of IEEE 754-2008)}, 
  title={IEEE Standard for Floating-Point Arithmetic}, 
  year={2019},
  volume={},
  number={},
  pages={1-84},
  keywords={IEEE Standards;Floating-point arithmetic;arithmetic;binary;computer;decimal;exponent;floating-point;format;IEEE 754;interchange;NaN;number;rounding;significand;subnormal.},
  doi={10.1109/IEEESTD.2019.8766229}
}

@article{blas,
    author = {Lawson, C. L. and Hanson, R. J. and Kincaid, D. R. and Krogh, F. T.},
    title = {Basic Linear Algebra Subprograms for Fortran Usage},
    year = {1979},
    issue_date = {1979},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {5},
    number = {3},
    issn = {0098-3500},
    url = {https://doi.org/10.1145/355841.355847},
    doi = {10.1145/355841.355847},
    journal = {ACM Trans. Math. Softw.},
    pages = {308–323},
    numpages = {16}
}

@inproceedings{lapack,
    author = {Anderson, E. and Bai, Z. and Dongarra, J. and Greenbaum, A. and McKenney, A. and Du Croz, J. and Hammarling, S. and Demmel, J. and Bischof, C. and Sorensen, D.},
    title = {LAPACK: a portable linear algebra library for high-performance computers},
    year = {1990},
    isbn = {0897914120},
    publisher = {IEEE Computer Society Press},
    address = {Washington, DC, USA},
    abstract = {The goal of the LAPACK project is to design and implement a portable linear algebra library for efficient use on a variety of high-performance computers. The library is based on the widely used LINPACK and EISPACK packages for solving linear equations, eigenvalue problems, and linear least-squares problems, but extends their functionality in a number of ways. The major methodology for making the algorithms run faster is to restructure them to perform block matrix operations (e.g., matrix-matrix multiplication) in their inner loops. These block operations may be optimized to exploit the memory hierarchy of a specific architecture. The LAPACK project is also working on new algorithms that yield higher relative accuracy for a variety of linear algebra problems.},
    booktitle = {Proceedings of the 1990 ACM/IEEE Conference on Supercomputing},
    pages = {2–11},
    numpages = {10},
    location = {New York, New York, USA},
    series = {Supercomputing '90}
}

@misc{wiki:Graphics_processing_unit,
   author = "Wikipedia",
   title = "{Graphics processing unit} --- {W}ikipedia{,} The Free Encyclopedia",
   year = "2024",
   howpublished = {\url{http://en.wikipedia.org/w/index.php?title=Graphics\%20processing\%20unit\&oldid=1227541994}}
 }

@misc{cuda,
    author = "NVIDIA",
    title = "CUDA C Programming Guide",
    year="2024",
    howpublished = {\url{https://docs.nvidia.com/cuda/cuda-c-programming-guide/}}
}

@ARTICLE{Dongarra2000,
  author={Dongarra, J. and Sullivan, F.},
  journal={Computing in Science \& Engineering}, 
  title={Guest Editors Introduction to the top 10 algorithms}, 
  year={2000},
  volume={2},
  number={1},
  pages={22-23},
  keywords={Linear algebra;History;Eigenvalues and eigenfunctions;Linear programming;Large-scale systems;Equations;Programmable control;Matrix decomposition;Sparse matrices;Art},
  doi={10.1109/MCISE.2000.814652}
}

@ARTICLE{Krylov1931,
  author={Krylov, A. N.},
  journal={SSSR Otd Mat. Estest}, 
  title={On the numerical solution of equations whose solution determine the frequency of small vibrations of material systems}, 
  year={1931},
  volume={1},
  pages={491-539},
}

@article{Arnoldi1951,
  title={The principle of minimized iterations in the solution of the matrix eigenvalue problem},
  author={Walter E. Arnoldi},
  journal={Quarterly of Applied Mathematics},
  year={1951},
  volume={9},
  pages={17-29},
  url={https://api.semanticscholar.org/CorpusID:115852469}
}

@ARTICLE{Mises1929,
       author = {{Mises}, R.~V. and {Pollaczek-Geiringer}, H.},
        title = "{Praktische Verfahren der Gleichungsaufl{\"o}sung .}",
      journal = {Zeitschrift Angewandte Mathematik und Mechanik},
         year = 1929,
        month = jan,
       volume = {9},
       number = {1},
        pages = {58-77},
          doi = {10.1002/zamm.19290090105},
}

@article{Francis1961,
    author = {Francis, J. G. F.},
    title = "{The QR Transformation A Unitary Analogue to the LR Transformation—Part 1}",
    journal = {The Computer Journal},
    volume = {4},
    number = {3},
    pages = {265-271},
    year = {1961},
    month = {01},
    abstract = "{The LR transformation, due to Rutishauser, has proved to be a powerful method for finding the eigenvalues of symmetric band matrices. Little attention, however, has been paid to its application to the more difficult problem of finding eigenvalues of general unsymmetric matrices. If the matrices are large two important difficulties are likely to occur. Firstly, triangular decomposition, which is the basis of the method, is by no means always numerically stable, and secondly, the amount of computation required by the method is likely to be very great. This paper describes an algorithm similar to the LR transformation except that the transformations involved in it are all unitary and can thus be expected to by numerically stable. It is then shown that there are various advantages in first converting the matrix to almost-triangular form; in particular, the amount of work involved in the algorithm can then be greatly reduced.Part 1 of the paper is largely concerned with proof of convergence, and the theoretical aspect. Part 2, to be published in January, discussed practical computation and gives results of experiments.}",
    issn = {0010-4620},
    doi = {10.1093/comjnl/4.3.265},
    eprint = {https://academic.oup.com/comjnl/article-pdf/4/3/265/1080833/040265.pdf},
}

@article{Lanczos1950,
    author = "Lanczos, Cornelius",
    title = "{An iteration method for the solution of the eigenvalue problem of linear differential and integral operators}",
    doi = "10.6028/jres.045.026",
    journal = "J. Res. Natl. Bur. Stand. B",
    volume = "45",
    pages = "255--282",
    year = "1950"
}

@Book{Golub1996,
  Title                    = {Matrix Computations},
  Author                   = {Golub, Gene H. and Van Loan, Charles F.},
  Publisher                = {The Johns Hopkins University Press},
  Year                     = {1996},
  Edition                  = {Third}
}

@article{Grimes1994,
    author = {Grimes, Roger G. and Lewis, John G. and Simon, Horst D.},
    title = {A Shifted Block Lanczos Algorithm for Solving Sparse Symmetric Generalized Eigenproblems},
    journal = {SIAM Journal on Matrix Analysis and Applications},
    volume = {15},
    number = {1},
    pages = {228-272},
    year = {1994},
    doi = {10.1137/S0895479888151111},
    abstract = { An “industrial strength” algorithm for solving sparse symmetric generalized eigenproblems is described. The algorithm has its foundations in known techniques in solving sparse symmetric eigenproblems, notably the spectral transformation of Ericsson and Ruhe and the block Lanczos algorithm. However, the combination of these two techniques is not trivial; there are many pitfalls awaiting the unwary implementor. The focus of this paper is on identifying those pitfalls and avoiding them, leading to a “bomb-proof” algorithm that can live as a black box eigensolver inside a large applications code. The code that results comprises a robust shift selection strategy and a block Lanczos algorithm that is a novel combination of new techniques and extensions of old techniques. }
}

@article{Householder1958,
    author = {Householder, Alston S.},
    title = {Unitary Triangularization of a Nonsymmetric Matrix},
    year = {1958},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {5},
    number = {4},
    issn = {0004-5411},
    url = {https://doi.org/10.1145/320941.320947},
    doi = {10.1145/320941.320947},
    journal = {J. ACM},
    pages = {339–342},
    numpages = {4}
}

@article{CPUvsGPU2019,
author = {Li, Feng and Ye, Yunming and Tian, Zhaoyang and Zhang, Xiaofeng},
year = {2019},
month = {08},
pages = {},
title = {CPU versus GPU: which can perform matrix computation faster—performance comparison for basic linear algebra subprograms},
volume = {31},
journal = {Neural Computing and Applications},
doi = {10.1007/s00521-018-3354-z}
}

%%%%% GRAM - SCHMIDT
% CGS
@article{cgs1974,
    author = {Kiełbasiński, A},
    title = {Analiza numeryczna algorytmu ortogonalizacji Grama-Schmidta},
    year = {1974},
    volume = {2},
    number = {2},
    url = {https://wydawnictwa.ptm.org.pl/index.php/matematyka-stosowana/article/viewArticle/1048},
    doi = {10.14708/ma.v2i2.1048},
    journal = {Journals of the Polish Mathematical Society},
    pages = {15-35},
}

% MGS
@article{Bjrck1967,
  title={Solving linear least squares problems by Gram-Schmidt orthogonalization},
  author={{\AA}ke Bj{\"o}rck},
  journal={BIT Numerical Mathematics},
  year={1967},
  volume={7},
  pages={1-21},
  url={https://api.semanticscholar.org/CorpusID:119767729}
}

% CGS2
@article{Giraud2005,
  title={Rounding error analysis of the classical Gram-Schmidt orthogonalization process},
  author={Luc Giraud and Julien Langou and Miroslav Rozlo{\vz}n{\'i}k and Jasper van den Eshof},
  journal={Numerische Mathematik},
  year={2005},
  volume={101},
  pages={87-100},
  url={https://api.semanticscholar.org/CorpusID:6900273}
}

@Article{Abdelmalek1971,
    author={Abdelmalek, Nabih N.},
    title={Round off error analysis for Gram-Schmidt method and solution of linear least squares problems},
    journal={BIT Numerical Mathematics},
    year={1971},
    volume={11},
    number={4},
    pages={345-367},
    keywords={numeric computing; mathematics, general; computational mathematics and numerical analysis},
    abstract={Round off error analysis for the classical Gram-Schmidt orthogonalization method with re-orthogonalization is presented. The effect of the round-off error on the orthogonality of the derived vectors and also on the solution of the linear least squares problems when solved by the Gram-Schmidt algorithm are given. Numerical results compared favorably with the results of other methods. The classical case when no re-orthogonalization takes place is also discussed.},
    note={Collection / Collection : NRC Publications Archive / Archives des publications du CNRC},
    note={Record identifier / Identificateur de l'enregistrement : 7f6a690a-2cba-47c6-96f5-e1cfbf6309cd},
    issn={1572-9125},
    doi={10.1007/BF01939404},
    url={https://doi.org/10.1007/BF01939404},
    language={eng}
}

@book{Parlett1998,
    author = {Parlett, Beresford N.},
    title = {The Symmetric Eigenvalue Problem},
    publisher = {Society for Industrial and Applied Mathematics},
    year = {1998},
    doi = {10.1137/1.9781611971163},
    address = {},
    edition   = {},
    URL = {https://epubs.siam.org/doi/abs/10.1137/1.9781611971163},
}


%CholQR
@article{cholQR2015,
    title = "Roundoff error analysis of the Cholesky QR2 algorithm",
    abstract = "We consider the QR decomposition of an m × n matrix X with full column rank, where m × n. Among the many algorithms available, the Cholesky QR algorithm is ideal from the viewpoint of high performance computing since it consists entirely of standard level 3 BLAS operations with large matrix sizes, and requires only one reduce and broadcast in parallel environments. Unfortunately, it is well-known that the algorithm is not numerically stable and the deviation from orthogonality of the computed Q factor is of order O((κ2(X))2u), where κ2(X) is the 2-norm condition number of X and u is the unit roundoff. In this paper, we show that if the condition number of X is not too large, we can greatly improve the stability by iterating the Cholesky QR algorithm twice. More specifically, if κ2(X) is at most O(u-1/2 ), both the residual and deviation from orthogonality are shown to be of order O(u). Numerical results support our theoretical analysis.",
    keywords = "Cholesky QR, Communication-avoiding algorithms, QR decomposition, Roundoff error analysis",
    author = "Yusaku Yamamoto and Yuji Nakatsukasa and Yuka Yanagisawa and Takeshi Fukaya",
    year = "2015",
    language = "English",
    volume = "44",
    pages = "306--326",
    journal = "Electronic Transactions on Numerical Analysis",
    issn = "1068-9613",
    publisher = "Kent State University",
}

%%%%% BGS

@article{Carson2022,
    title = {Block Gram-Schmidt algorithms and their stability properties},
    journal = {Linear Algebra and its Applications},
    volume = {638},
    pages = {150-195},
    year = {2022},
    issn = {0024-3795},
    doi = {https://doi.org/10.1016/j.laa.2021.12.017},
    url = {https://www.sciencedirect.com/science/article/pii/S0024379521004523},
    author = {Erin Carson and Kathryn Lund and Miroslav Rozložník and Stephen Thomas},
    keywords = {Gram-Schmidt, Block Krylov subspace methods, Stability, Loss of orthogonality},
    abstract = {Block Gram-Schmidt algorithms serve as essential kernels in many scientific computing applications, but for many commonly used variants, a rigorous treatment of their stability properties remains open. This work provides a comprehensive categorization of block Gram-Schmidt algorithms, particularly those used in Krylov subspace methods to build orthonormal bases one block vector at a time. Known stability results are assembled, and new results are summarized or conjectured for important communication-reducing variants. Additionally, new block versions of low-synchronization variants are derived, and their efficacy and stability are demonstrated for a wide range of challenging examples. Numerical examples are computed with a versatile Matlab package hosted at https://github.com/katlund/BlockStab, and scripts for reproducing all results in the paper are provided. Block Gram-Schmidt implementations in popular software packages are discussed, along with a number of open problems. An appendix containing all algorithms type-set in a uniform fashion is provided.}
}

% BCGS
@article{Jalby1991,
    author = {Jalby, W. and Philippe, B.},
    title = {Stability Analysis and Improvement of the Block Gram–Schmidt Algorithm},
    journal = {SIAM Journal on Scientific and Statistical Computing},
    volume = {12},
    number = {5},
    pages = {1058-1073},
    year = {1991},
    doi = {10.1137/0912056},
    URL = {https://doi.org/10.1137/0912056},
    abstract = { The advent of supercomputers with hierarchical memory systems has imposed the use of block algorithms for the linear algebra algorithms. Although block algorithms may result in impressive improvements in performance, their numerical properties are quite different from their scalar counterpart and deserve an in-depth study. In this paper, the numerical stability of block Gram–Schmidt orthogonalization is studied and a variant is proposed which has numerical properties similar to the modified Gram–Schmidt procedure while retaining most of the performance advantages of the block formulation. }
}

%BCGS2
@article{Barlow2013,
    title = "Reorthogonalized block classical Gram-Schmidt",
    abstract = "A reorthogonalized block classical Gram-Schmidt algorithm is proposed that factors a full column rank matrix A into A = QR where Q is left orthogonal (has orthonormal columns) and R is upper triangular and nonsingular. This block Gram-Schmidt algorithm can be implemented using matrix-matrix operations making it more efficient on modern architectures than orthogonal factorization algorithms based upon matrix-vector operations and purely vector operations. Gram-Schmidt orthogonal factorizations are important in the stable implementation of Krylov space methods such as GMRES and in approaches to modifying orthogonal factorizations when columns and rows are added or deleted from a matrix. With appropriate assumptions about the diagonal blocks of R, the algorithm, when implemented in floating point arithmetic with machine unit ε M, produces Q and R such that {double pipe}I - QT Q{double pipe} = O(εM) and {double pipe}A - QR{double pipe} = O(εM{double pipe}A{double pipe}). The first of these bounds has not been shown for a block Gram-Schmidt procedure before. As consequence of these results, we provide a different analysis, with a slightly different assumption, that re-establishes a bound of Giraud et al. (Num Math, 101(1):87-100, 2005) for the CGS2 algorithm.",
    author = "Barlow, {Jesse L.} and Alicja Smoktunowicz",
    note = "Funding Information: The research of J. L. Barlow was sponsored by the National Science Foundation under contract no. CCF-1115704. ",
    year = "2013",
    month = mar,
    doi = "10.1007/s00211-012-0496-2",
    language = "English (US)",
    volume = "123",
    pages = "395--423",
    journal = "Numerische Mathematik",
    issn = "0029-599X",
    publisher = "Springer New York",
    number = "3",
}

@misc{intelMKL,
    author = {Intel},
    title = {Intel oneAPI Math Kernel Library},
    url = {https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html}
}

@misc{cuBLAS,
    author = {NVIDIA},
    title = {cuBLAS},
    url = {https://docs.nvidia.com/cuda/cublas/}
}

@misc{GpuSpec,
    author = {Wikipedia},
    title = {List of Nvidia graphics processing units},
    url = {https://en.wikipedia.org/wiki/List_of_Nvidia_graphics_processing_units}
}

@manual{Lapack41,
    author = {Blackford, S. and Dongarra, J.},
    title = {LAPACK Working note 41},
    year = {1999},
    pages = {118},
    url = {https://www.netlib.org/lapack/lawnspdf/lawn41.pdf}
}

@article{Soar2005,
    author = {Bai, Zhaojun and Su, Yangfeng},
    title = {SOAR: A Second-order Arnoldi Method for the Solution of the Quadratic Eigenvalue Problem},
    journal = {SIAM Journal on Matrix Analysis and Applications},
    volume = {26},
    number = {3},
    pages = {640-659},
    year = {2005},
    doi = {10.1137/S0895479803438523},
    abstract = { We first introduce a second-order Krylov subspace \$\mathcal{G}\_n\$(A,B;u) based on a pair of square matrices A and B and a vector u. The subspace is spanned by a sequence of vectors defined via a second-order linear homogeneous recurrence relation with coefficient matrices A and B and an initial vector u. It generalizes the well-known Krylov subspace \$\mathcal{K}\_n\$(A;v), which is spanned by a sequence of vectors defined via a first-order linear homogeneous recurrence relation with a single coefficient matrix A and an initial vector v. Then we present a second-order Arnoldi (SOAR) procedure for generating an orthonormal basis of \$\mathcal{G}\_n\$(A,B;u). By applying the standard Rayleigh--Ritzorthogonal projection technique, we derive an SOAR method for solving a large-scale quadratic eigenvalue problem (QEP). This method is applied to the QEP directly. Hence it preserves essential structures and properties of the QEP. Numerical examples demonstrate that the SOAR method outperforms convergence behaviors of the Krylov subspace--based Arnoldi method applied to the linearized QEP. }
}


@article{toar2016,
    author = {Lu, Ding and Su, Yangfeng and Bai, Zhaojun},
    title = {Stability Analysis of the Two-level Orthogonal Arnoldi Procedure},
    journal = {SIAM Journal on Matrix Analysis and Applications},
    volume = {37},
    number = {1},
    pages = {195-214},
    year = {2016},
    doi = {10.1137/151005142},
    abstract = { The second-order Arnoldi (SOAR) procedure is an algorithm for computing an orthonormal basis of the second-order Krylov subspace. It has found applications in solving quadratic eigenvalue problems and model order reduction of second-order dynamical systems among others. Unfortunately, the SOAR procedure can be numerically unstable. The two-level orthogonal Arnoldi (TOAR) procedure has been proposed as an alternative to SOAR to cure the numerical instability. In this paper, we provide a rigorous stability analysis of the TOAR procedure. We prove that under mild assumptions, the TOAR procedure is backward stable in computing an orthonormal basis of the associated linear Krylov subspace. The benefit of the backward stability of TOAR is demonstrated by its high accuracy in structure-preserving model order reduction of second-order dynamical systems. }
}





@article{Tisseur2001,
    author = {Tisseur, Fran\c{c}oise and Meerbergen, Karl},
    title = {The Quadratic Eigenvalue Problem},
    journal = {SIAM Review},
    volume = {43},
    number = {2},
    pages = {235-286},
    year = {2001},
    doi = {10.1137/S0036144500381988},
    abstract = { We survey the quadratic eigenvalue problem, treating its many applications, its mathematical properties, and a variety of numerical solution techniques. Emphasis is given to exploiting both the structure of the matrices in the problem (dense, sparse, real, complex, Hermitian, skew-Hermitian) and the spectral properties of the problem. We classify numerical methods and catalogue available software. }
}

@misc{SparseMatrixPNG,
    author = {Wikipedi},
    title = {A sparse matrix obtained when solving a finite element problem in two dimensions. The non-zero elements are shown in black},
    url = {https://en.wikipedia.org/wiki/Sparse_matrix}
}

@misc{cuSPARSE,
    author = {NVIDIA},
    title = {cuSPARSE},
    url = {https://docs.nvidia.com/cuda/cusparse/index.html}
}

@misc{cuDSS,
    author = {NVIDIA},
    title = {cuDSS},
    url = {https://developer.nvidia.com/cudss}
}

@article{Mumps2001,
  title={A Fully Asynchronous Multifrontal Solver Using Distributed Dynamic Scheduling},
  author={Patrick R. Amestoy and Iain S. Duff and Jean-Yves L’Excellent and Jacko Koster},
  journal={SIAM J. Matrix Anal. Appl.},
  year={2001},
  volume={23},
  pages={15-41},
  url={https://api.semanticscholar.org/CorpusID:2329523}
}

@article{Pardiso2000,
  title={Efficient Sparse LU Factorization with Left-Right Looking Strategy on Shared Memory Multiprocessors},
  author={Olaf Schenk and Klaus G{\"a}rtner and Wolfgang Fichtner},
  journal={BIT Numerical Mathematics},
  year={2000},
  volume={40},
  pages={158-176},
  url={https://api.semanticscholar.org/CorpusID:59634216}
}

@article{GLU2019,
  author       = {Shaoyi Peng and
                  Sheldon X.{-}D. Tan},
  title        = {{GLU3.0:} Fast GPU-based Parallel Sparse {LU} Factorization for Circuit
                  Simulation},
  journal      = {CoRR},
  volume       = {abs/1908.00204},
  year         = {2019},
  url          = {http://arxiv.org/abs/1908.00204},
  eprinttype    = {arXiv},
  eprint       = {1908.00204},
  timestamp    = {Fri, 09 Aug 2019 12:15:56 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1908-00204.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{CHOLMOD2008,
    author = {Chen, Yanqing and Davis, Timothy A. and Hager, William W. and Rajamanickam, Sivasankaran},
    title = {Algorithm 887: CHOLMOD, Supernodal Sparse Cholesky Factorization and Update/Downdate},
    year = {2008},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {35},
    number = {3},
    issn = {0098-3500},
    url = {https://doi.org/10.1145/1391989.1391995},
    doi = {10.1145/1391989.1391995},
    abstract = {CHOLMOD is a set of routines for factorizing sparse symmetric positive definite matrices of the form A or AAT, updating/downdating a sparse Cholesky factorization, solving linear systems, updating/downdating the solution to the triangular system Lx = b, and many other sparse matrix functions for both symmetric and unsymmetric matrices. Its supernodal Cholesky factorization relies on LAPACK and the Level-3 BLAS, and obtains a substantial fraction of the peak performance of the BLAS. Both real and complex matrices are supported. CHOLMOD is written in ANSI/ISO C, with both C and MATLABTM interfaces. It appears in MATLAB 7.2 as x=Ab when A is sparse symmetric positive definite, as well as in several other sparse matrix functions.},
    journal = {ACM Trans. Math. Softw.},
    articleno = {22},
    numpages = {14},
    keywords = {Cholesky factorization, linear equations, sparse matrices}
}